{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b5ec6b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import wandb \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "13a94fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Step</td><td>▁▁▁▁▂▁▁▁▁▂▂▃▃▄▅▄▆▆▆▇▃▃▄▄▅▆▆▇▇▇▂▂▂▃▃▄▅▅▆█</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>perplexity</td><td>▄▅▅▆▆▆▆▆▇█▇▇▇▆▆▇▇▄▇▇▇▇▇▇▇▁▁▁▁▁▁▁▁▁▁▆▅▅▅▅</td></tr><tr><td>recon_error</td><td>█▄▂▃▁▁▁▁▁▁▅▃▂▂▁▁▁▁▁▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Step</td><td>4950</td></tr><tr><td>loss</td><td>0.0</td></tr><tr><td>perplexity</td><td>17.76886</td></tr><tr><td>recon_error</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">daily-puddle-11</strong> at: <a href='https://wandb.ai/hangoebl-j-johannes-kepler-universit-t-linz/image-rq-vae/runs/21bx30th' target=\"_blank\">https://wandb.ai/hangoebl-j-johannes-kepler-universit-t-linz/image-rq-vae/runs/21bx30th</a><br> View project at: <a href='https://wandb.ai/hangoebl-j-johannes-kepler-universit-t-linz/image-rq-vae' target=\"_blank\">https://wandb.ai/hangoebl-j-johannes-kepler-universit-t-linz/image-rq-vae</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250411_150805-21bx30th\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Justin\\Documents\\Master-Thesis\\Semantic-ID\\wandb\\run-20250411_155653-c5q8nbhj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hangoebl-j-johannes-kepler-universit-t-linz/image-rq-vae/runs/c5q8nbhj' target=\"_blank\">flowing-durian-12</a></strong> to <a href='https://wandb.ai/hangoebl-j-johannes-kepler-universit-t-linz/image-rq-vae' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hangoebl-j-johannes-kepler-universit-t-linz/image-rq-vae' target=\"_blank\">https://wandb.ai/hangoebl-j-johannes-kepler-universit-t-linz/image-rq-vae</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hangoebl-j-johannes-kepler-universit-t-linz/image-rq-vae/runs/c5q8nbhj' target=\"_blank\">https://wandb.ai/hangoebl-j-johannes-kepler-universit-t-linz/image-rq-vae/runs/c5q8nbhj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    entity=\"hangoebl-j-johannes-kepler-universit-t-linz\",\n",
    "    project=\"image-rq-vae\",\n",
    "    config={\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"architecture\": \"RQ-VAE\",\n",
    "        \"dataset\": \"MNIST\",\n",
    "        \"epochs\": 5000,\n",
    "    },\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "62495028",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):        \n",
    "    def __init__(self, in_dim, h_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        kernel = 4\n",
    "        stride = 2\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            nn.Conv2d(in_dim, h_dim // 2, kernel_size=kernel,\n",
    "                      stride=stride, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(h_dim // 2, h_dim, kernel_size=kernel,\n",
    "                      stride=stride, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(h_dim, h_dim, kernel_size=kernel-1,\n",
    "                      stride=stride-1, padding=1),\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_stack(x)\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_dim, h_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        kernel = 4\n",
    "        stride = 2\n",
    "\n",
    "        self.inverse_conv_stack = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_dim, h_dim, kernel_size=kernel-1, stride=stride-1, padding=1),\n",
    "            nn.ConvTranspose2d(h_dim, h_dim // 2,\n",
    "                               kernel_size=kernel, stride=stride, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(h_dim//2, 1, kernel_size=kernel,\n",
    "                               stride=stride, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.inverse_conv_stack(x)\n",
    "    \n",
    "class VectorQuantizer(nn.Module):\n",
    "    def __init__(self, n_e, e_dim, beta):\n",
    "        super(VectorQuantizer, self).__init__()\n",
    "        self.n_e = n_e\n",
    "        self.e_dim = e_dim\n",
    "        self.beta = beta\n",
    "\n",
    "        self.embedding = nn.Embedding(self.n_e, self.e_dim)\n",
    "        self.embedding.weight.data.uniform_(-1.0 / self.n_e, 1.0 / self.n_e)\n",
    "\n",
    "    def forward(self, z):\n",
    "        # reshape z -> (batch, height, width, channel) and flatten\n",
    "        z = z.permute(0, 2, 3, 1).contiguous()\n",
    "        z_flattened = z.view(-1, self.e_dim)\n",
    "        # distances from z to embeddings e_j (z - e)^2 = z^2 + e^2 - 2 e * z\n",
    "\n",
    "        d = torch.sum(z_flattened ** 2, dim=1, keepdim=True) + \\\n",
    "            torch.sum(self.embedding.weight**2, dim=1) - 2 * \\\n",
    "            torch.matmul(z_flattened, self.embedding.weight.t())\n",
    "\n",
    "        # find closest encodings\n",
    "        min_encoding_indices = torch.argmin(d, dim=1).unsqueeze(1)\n",
    "        min_encodings = torch.zeros(\n",
    "            min_encoding_indices.shape[0], self.n_e).to(device)\n",
    "        min_encodings.scatter_(1, min_encoding_indices, 1)\n",
    "\n",
    "        # get quantized latent vectors\n",
    "        z_q = torch.matmul(min_encodings, self.embedding.weight).view(z.shape)\n",
    "\n",
    "        # compute loss for embedding\n",
    "        loss = torch.mean((z_q.detach()-z)**2) + self.beta * \\\n",
    "            torch.mean((z_q - z.detach()) ** 2)\n",
    "\n",
    "        # preserve gradients\n",
    "        z_q = z + (z_q - z).detach()\n",
    "\n",
    "        # perplexity\n",
    "        e_mean = torch.mean(min_encodings, dim=0)\n",
    "        perplexity = torch.exp(-torch.sum(e_mean * torch.log(e_mean + 1e-10)))\n",
    "\n",
    "        # reshape back to match original input shape\n",
    "        z_q = z_q.permute(0, 3, 1, 2).contiguous()\n",
    "\n",
    "        return loss, z_q, perplexity, min_encodings, min_encoding_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7882b88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQVAE(nn.Module):\n",
    "    def __init__(self, h_dim,\n",
    "                 n_embeddings, embedding_dim, beta, save_img_embedding_map=False):\n",
    "        super(VQVAE, self).__init__()\n",
    "        # encode image into continuous latent space\n",
    "        self.encoder = Encoder(1, h_dim)\n",
    "        self.pre_quantization_conv = nn.Conv2d(\n",
    "            h_dim, embedding_dim, kernel_size=1, stride=1)\n",
    "        # pass continuous latent vector through discretization bottleneck\n",
    "        self.vector_quantization = VectorQuantizer(\n",
    "            n_embeddings, embedding_dim, beta)\n",
    "        # decode the discrete latent representation\n",
    "        self.decoder = Decoder(embedding_dim, h_dim)\n",
    "\n",
    "        if save_img_embedding_map:\n",
    "            self.img_to_embedding_map = {i: [] for i in range(n_embeddings)}\n",
    "        else:\n",
    "            self.img_to_embedding_map = None\n",
    "\n",
    "    def forward(self, x, verbose=False):\n",
    "\n",
    "        z_e = self.encoder(x)\n",
    "\n",
    "        z_e = self.pre_quantization_conv(z_e)\n",
    "        embedding_loss, z_q, perplexity, min_encodings, min_encodings_idx = self.vector_quantization(\n",
    "            z_e)\n",
    "        x_hat = self.decoder(z_q)\n",
    "\n",
    "        if verbose:\n",
    "            print('original data shape:', x.shape)\n",
    "            print('encoded data shape:', z_e.shape)\n",
    "            print('recon data shape:', x_hat.shape)\n",
    "            assert False\n",
    "\n",
    "        return embedding_loss, x_hat, perplexity, z_q, min_encodings, min_encodings_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dc539a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6172.850482291342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VQVAE: 100%|██████████| 5000/5000 [05:13<00:00, 15.95epoch/s, Recon_Error=1.9656215499708196e-06, Loss=2.0383506580401445e-06, Perplexity=18.412446975708008]\n"
     ]
    }
   ],
   "source": [
    "h_dim = 128\n",
    "n_embeddings = 512\n",
    "embedding_dim = 64\n",
    "beta = 0.25\n",
    "save_img_embedding_map = False\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs = 5000\n",
    "log_interval = 50\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "model = VQVAE(h_dim,\n",
    "                 n_embeddings, embedding_dim, beta, save_img_embedding_map).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, amsgrad=True)\n",
    "\n",
    "model.train()\n",
    "\n",
    "results = {\n",
    "    'n_updates': 0,\n",
    "    'recon_errors': [],\n",
    "    'loss_vals': [],\n",
    "    'perplexities': [],\n",
    "}\n",
    "\n",
    "train_dataset = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
    "x_train_var = np.var(train_dataset.data.numpy())\n",
    "print(x_train_var)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "def train():\n",
    "    pbar = tqdm(range(epochs),total=epochs, desc=\"Training VQVAE\", unit=\"epoch\")\n",
    "    for i in pbar:\n",
    "        (x, _) = next(iter(train_loader))\n",
    "        x = x.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        embedding_loss, x_hat, perplexity, _, _, _ = model(x)\n",
    "        recon_loss = torch.mean((x_hat - x)**2) / x_train_var\n",
    "        loss = recon_loss + embedding_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        results[\"recon_errors\"].append(recon_loss.cpu().detach().numpy())\n",
    "        results[\"perplexities\"].append(perplexity.cpu().detach().numpy())\n",
    "        results[\"loss_vals\"].append(loss.cpu().detach().numpy())\n",
    "        results[\"n_updates\"] = i\n",
    "\n",
    "        if i % log_interval == 0:\n",
    "            recon_error = np.mean(results[\"recon_errors\"][-log_interval:])\n",
    "            loss = np.mean(results[\"loss_vals\"][-log_interval:])\n",
    "            perplexity = np.mean(results[\"perplexities\"][-log_interval:])\n",
    "            \n",
    "\n",
    "            wandb.log({\n",
    "                'Step': i,\n",
    "                'recon_error': recon_error,\n",
    "                'loss': loss,\n",
    "                'perplexity': perplexity,\n",
    "            })\n",
    "        pbar.set_postfix({\n",
    "            \"Recon_Error\":f\"{recon_error}\",\n",
    "            \"Loss\":f\"{loss}\",\n",
    "            \"Perplexity\":f\"{perplexity}\"}\n",
    "        )\n",
    "    pbar.close()\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "eb689e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([49, 1])"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.5), np.float64(27.5), np.float64(27.5), np.float64(-0.5))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = datasets.MNIST(root='data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "# Step 3: Select a random image from the test set\n",
    "random_idx = 1\n",
    "image, label = test_dataset[random_idx]\n",
    "image = image.unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
    "\n",
    "# Step 4: Pass the image through your model (encoder + quantizer + decoder)\n",
    "with torch.no_grad():  # Disable gradient computation for inference\n",
    "    embedding_loss, x_hat, perplexity, z_q, min_encodings, min_encodings_idx = model(image)\n",
    "    print(min_encodings_idx.shape)\n",
    "\n",
    "from torchvision.transforms import ToPILImage\n",
    "# Step 5: Convert the original and reconstructed images to PIL format for display\n",
    "to_pil_image = ToPILImage()\n",
    "\n",
    "# Original image\n",
    "original_image = image.squeeze(0).cpu()  # Remove batch dimension and move to CPU\n",
    "original_image_pil = to_pil_image(original_image)\n",
    "\n",
    "# Decoded (reconstructed) image\n",
    "decoded_image = x_hat.squeeze(0).cpu()  # Remove batch dimension and move to CPU\n",
    "decoded_image_pil = to_pil_image(decoded_image)\n",
    "\n",
    "# Step 6: Display the original and decoded images side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axes[0].imshow(original_image_pil, cmap='gray')\n",
    "axes[0].set_title(f\"Original Label: {label}\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(decoded_image_pil, cmap='gray')\n",
    "axes[1].set_title(\"Decoded Image\")\n",
    "axes[1].axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
